# Pixell Agent Framework Environment Configuration
# Copy this file to .env.local and update the values for your environment

# =============================================================================
# SERVICE CONFIGURATION
# =============================================================================
# URL where the PAF Core Agent is running (web connects directly)
# For local development: http://localhost:8000
# For production: https://your-paf-core-agent.com
PAF_CORE_AGENT_URL=http://localhost:8000

# PAF Core Agent connection strategy
# Options: grpc | http | auto (default: auto)
# - grpc: Force gRPC connection only
# - http: Force HTTP/REST connection only
# - auto: Try gRPC first, fallback to HTTP on failure (recommended)
PAF_CORE_CONNECTION_STRATEGY=auto

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================
# Base URL for the web application
NEXT_PUBLIC_BASE_URL=http://localhost:3003

# =============================================================================
# AI PROVIDER CONFIGURATION
# =============================================================================
# Default AI provider (openai, anthropic, aws-bedrock, azure-openai, google-ai)
AI_DEFAULT_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
OPENAI_ORGANIZATION=your_org_id_here
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# AWS Bedrock Configuration
AWS_ACCESS_KEY_ID=your_aws_access_key_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_key_here
AWS_REGION=us-east-1
AWS_BEDROCK_MODEL=anthropic.claude-3-sonnet-20240229-v1:0

# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your_azure_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=your_deployment_name
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Google AI Configuration
GOOGLE_AI_API_KEY=your_google_ai_api_key_here
GOOGLE_AI_MODEL=gemini-pro

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# Database connection settings
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=postgres
DB_NAME=postgres
DATABASE_URL=postgres://postgres:postgres@localhost:5432/postgres

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================
# Choose storage provider: local | s3
STORAGE_PROVIDER=local

# Local storage root (will be org-scoped under this directory)
STORAGE_LOCAL_PATH=./workspace-files

# S3 storage settings (used when STORAGE_PROVIDER=s3)
# Per-org bucket is derived automatically as paf-org-<org-slug>-<hash>.
# You can override with STORAGE_S3_BUCKET but it is optional.
STORAGE_S3_BUCKET=
STORAGE_S3_REGION=us-east-2
# Optional: custom endpoint for S3-compatible storage (e.g., MinIO)
S3_FILE_STORAGE_URL=
STORAGE_S3_ACCESS_KEY_ID=
STORAGE_S3_SECRET_ACCESS_KEY=

# Prefix under which org workspaces live inside the bucket.
# Effective prefix becomes: orgs/<orgId>/<STORAGE_S3_PREFIX>
STORAGE_S3_PREFIX=workspace-files

# Prefix within each bucket where workspace files live
STORAGE_S3_ORG_SCOPED=true

# =============================================================================
# STRIPE CONFIGURATION (Optional)
# =============================================================================
# Stripe payment processing
STRIPE_SECRET_KEY=sk_test_your_stripe_secret_key_here
STRIPE_PUBLISHABLE_KEY=pk_test_your_stripe_publishable_key_here
STRIPE_WEBHOOK_SECRET=whsec_your_webhook_secret_here

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================
# Debug mode
DEBUG=false

# Agent runtime framework
AGENT_RUNTIME=aws-strand

# Context token limits
MAX_CONTEXT_TOKENS=4000
DEFAULT_MODEL=gpt-3.5-turbo
